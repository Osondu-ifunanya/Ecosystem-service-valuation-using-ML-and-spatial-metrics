{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8xsKk9O71VvPdYnmLB8qz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Osondu-ifunanya/Ecosystem-service-valuation-using-ML-and-spatial-metrics/blob/main/Ecosystem%20service%20valuation%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmpxa3wNM-mL"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "rainfall_runoff_lstm.py\n",
        "\n",
        "Rainfall-runoff modeling with LSTM using synthetic basin-level inputs.\n",
        "\n",
        "Produces:\n",
        " - synthetic time series for multiple basins\n",
        " - LSTM model training and evaluation\n",
        " - RMSE and Nash-Sutcliffe Efficiency (NSE)\n",
        " - plots of observed vs predicted streamflow\n",
        " - exports predictions to Excel\n",
        "\n",
        "Requires:\n",
        "    pip install numpy pandas matplotlib scikit-learn tensorflow openpyxl\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "import os\n",
        "\n",
        "# ---------------------------\n",
        "# Utility: Nash-Sutcliffe Efficiency\n",
        "# ---------------------------\n",
        "def nse(observed, simulated):\n",
        "    obs = np.array(observed)\n",
        "    sim = np.array(simulated)\n",
        "    denom = np.sum((obs - obs.mean())**2)\n",
        "    if denom == 0:\n",
        "        return np.nan\n",
        "    return 1 - np.sum((sim - obs)**2) / denom\n",
        "\n",
        "# ---------------------------\n",
        "# 1) Generate synthetic basin-level time series\n",
        "# ---------------------------\n",
        "def generate_synthetic_basin_series(n_days=365*4, n_basins=5, seed=42):\n",
        "    \"\"\"\n",
        "    Generate synthetic daily timeseries for multiple basins.\n",
        "    Features: rainfall (mm), temperature (C), antecedent soil moisture (0-1)\n",
        "    Target: streamflow (m3/s) â€” synthetic function of rainfall and antecedent moisture\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    dates = pd.date_range(\"2015-01-01\", periods=n_days, freq=\"D\")\n",
        "\n",
        "    all_basins = {}\n",
        "    for b in range(n_basins):\n",
        "        # seasonal rainfall pattern (sinusoid) + random storms\n",
        "        seasonal = 20 + 15 * np.sin(2 * np.pi * (np.arange(n_days) % 365) / 365 + rng.uniform(0, 2*np.pi))\n",
        "        rainfall = np.maximum(0, seasonal * 0.2 * rng.normal(1.0, 0.3, n_days) + rng.exponential(3.0, n_days))\n",
        "        # reduce rainfall in dry basins somewhat\n",
        "        rainfall *= rng.uniform(0.6, 1.4)\n",
        "\n",
        "        # temperature seasonal\n",
        "        temp = 10 + 8 * np.sin(2 * np.pi * (np.arange(n_days) % 365) / 365 + rng.uniform(0, 2*np.pi)) + rng.normal(0, 1.5, n_days)\n",
        "\n",
        "        # antecedent soil moisture evolves with rainfall and evapotranspiration\n",
        "        soil = np.zeros(n_days)\n",
        "        soil[0] = rng.uniform(0.2, 0.6)\n",
        "        for t in range(1, n_days):\n",
        "            recharge = 0.02 * rainfall[t-1]  # small fraction\n",
        "            evap = 0.01 * max(0, temp[t-1]-5)\n",
        "            soil[t] = np.clip(soil[t-1] + recharge - evap + rng.normal(0, 0.005), 0, 1)\n",
        "\n",
        "        # true streamflow: nonlinear function: baseflow + quickflow from recent storms modulated by soil moisture\n",
        "        baseflow = 0.5 + 0.5 * rng.uniform(0.5, 1.5)  # basin-specific base\n",
        "        runoff = np.zeros(n_days)\n",
        "        for t in range(n_days):\n",
        "            # quick response from recent rainfall (last 3 days)\n",
        "            recent_rain = rainfall[max(0, t-3):t+1].sum()\n",
        "            quick = 0.1 * recent_rain * (0.5 + soil[t])  # wetter soils lead to higher quickflow here (synthetic choice)\n",
        "            seasonal_factor = 1 + 0.3 * np.sin(2*np.pi*(t%365)/365)\n",
        "            runoff[t] = max(0, baseflow * seasonal_factor + quick + rng.normal(0, baseflow*0.2))\n",
        "\n",
        "        df = pd.DataFrame({\n",
        "            \"date\": dates,\n",
        "            \"rainfall_mm\": rainfall,\n",
        "            \"temperature_C\": temp,\n",
        "            \"soil_moisture\": soil,\n",
        "            \"streamflow_m3s\": runoff\n",
        "        })\n",
        "        all_basins[f\"basin_{b+1:02d}\"] = df\n",
        "\n",
        "    return all_basins\n",
        "\n",
        "# ---------------------------\n",
        "# 2) Prepare sequences for LSTM\n",
        "# ---------------------------\n",
        "def create_sequences(df, input_cols, target_col, seq_len=14, horizon=1):\n",
        "    \"\"\"\n",
        "    Convert a DataFrame for one basin into sequences for LSTM.\n",
        "    - seq_len: number of past days used as input\n",
        "    - horizon: days ahead to predict (1 -> next day)\n",
        "    Returns X (n_samples, seq_len, n_features), y (n_samples,)\n",
        "    \"\"\"\n",
        "    data = df[input_cols].values\n",
        "    target = df[target_col].values\n",
        "    n = len(df)\n",
        "    X, y = [], []\n",
        "    for i in range(seq_len, n - horizon + 1):\n",
        "        X.append(data[i-seq_len:i, :])\n",
        "        y.append(target[i + horizon - 1])  # predict runoff at time i+horizon-1\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# ---------------------------\n",
        "# 3) Build and train LSTM model\n",
        "# ---------------------------\n",
        "def build_lstm_model(n_timesteps, n_features, n_units=64, dropout=0.2):\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(n_timesteps, n_features)),\n",
        "        layers.LSTM(n_units, return_sequences=True),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.LSTM(n_units//2, return_sequences=False),\n",
        "        layers.Dropout(dropout*0.5),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(1, activation='linear')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "# ---------------------------\n",
        "# 4) Main pipeline\n",
        "# ---------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # settings\n",
        "    N_BASINS = 6\n",
        "    N_DAYS = 365 * 3  # 3 years daily\n",
        "    SEQ_LEN = 21      # use 21 days of history\n",
        "    HORIZON = 1\n",
        "    TEST_FRACTION = 0.2\n",
        "    RANDOM_SEED = 42\n",
        "\n",
        "    # generate synthetic data\n",
        "    basins = generate_synthetic_basin_series(n_days=N_DAYS, n_basins=N_BASINS, seed=RANDOM_SEED)\n",
        "    print(f\"Generated synthetic data for {len(basins)} basins, {N_DAYS} days each.\")\n",
        "\n",
        "    # concatenate basins into one dataset for training (multi-site approach)\n",
        "    input_cols = [\"rainfall_mm\", \"temperature_C\", \"soil_moisture\"]\n",
        "    target_col = \"streamflow_m3s\"\n",
        "\n",
        "    X_list, y_list, meta = [], [], []\n",
        "    for basin_name, df in basins.items():\n",
        "        Xb, yb = create_sequences(df, input_cols, target_col, seq_len=SEQ_LEN, horizon=HORIZON)\n",
        "        # keep dates aligned for exports later\n",
        "        dates = df['date'].values[SEQ_LEN - 1: len(df) - HORIZON + 1]\n",
        "        # append\n",
        "        X_list.append(Xb)\n",
        "        y_list.append(yb)\n",
        "        meta.append(pd.DataFrame({\n",
        "            \"basin\": basin_name,\n",
        "            \"date\": dates[:len(yb)]\n",
        "        }))\n",
        "\n",
        "    X_all = np.vstack(X_list)\n",
        "    y_all = np.hstack(y_list)\n",
        "    meta_all = pd.concat(meta, ignore_index=True)\n",
        "    print(\"Total samples (pooled):\", X_all.shape[0])\n",
        "\n",
        "    # Split into training and test by time-block per-basin to avoid leakage:\n",
        "    # We'll split meta_all sequentially per-basin: simpler approach: use first (1-test_frac) portion for train per basin\n",
        "    # Build boolean mask for train/test samples\n",
        "    train_mask = np.zeros(len(meta_all), dtype=bool)\n",
        "    idx = 0\n",
        "    for basin_name, df in basins.items():\n",
        "        n_samples_basin = len(df) - SEQ_LEN - (HORIZON - 1)\n",
        "        n_train = int(np.floor((1 - TEST_FRACTION) * n_samples_basin))\n",
        "        train_mask[idx: idx + n_train] = True\n",
        "        idx += n_samples_basin\n",
        "    test_mask = ~train_mask\n",
        "\n",
        "    X_train = X_all[train_mask]\n",
        "    y_train = y_all[train_mask]\n",
        "    X_test = X_all[test_mask]\n",
        "    y_test = y_all[test_mask]\n",
        "    meta_test = meta_all[test_mask].reset_index(drop=True)\n",
        "\n",
        "    print(\"Train samples:\", X_train.shape[0], \"Test samples:\", X_test.shape[0])\n",
        "\n",
        "    # Scale features (fit scaler on training data only)\n",
        "    n_features = X_all.shape[2]\n",
        "    scaler = StandardScaler()\n",
        "    # reshape to 2D for scaler\n",
        "    X_train_2d = X_train.reshape(-1, n_features)\n",
        "    X_test_2d = X_test.reshape(-1, n_features)\n",
        "    scaler.fit(X_train_2d)\n",
        "    X_train_s = scaler.transform(X_train_2d).reshape(X_train.shape)\n",
        "    X_test_s = scaler.transform(X_test_2d).reshape(X_test.shape)\n",
        "\n",
        "    # Scale target? We'll predict streamflow in original units; optionally log-transform\n",
        "    # use log1p transform to stabilize variance\n",
        "    y_train_log = np.log1p(y_train)\n",
        "    y_test_log = np.log1p(y_test)\n",
        "\n",
        "    # Build model\n",
        "    model = build_lstm_model(n_timesteps=SEQ_LEN, n_features=n_features, n_units=128, dropout=0.2)\n",
        "    model.summary()\n",
        "\n",
        "    # Callbacks\n",
        "    cb = [\n",
        "        callbacks.EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n",
        "        callbacks.ModelCheckpoint(\"best_lstm_runoff.h5\", save_best_only=True, monitor='val_loss')\n",
        "    ]\n",
        "\n",
        "    # Train (use a validation split from training set)\n",
        "    history = model.fit(\n",
        "        X_train_s, y_train_log,\n",
        "        validation_split=0.15,\n",
        "        epochs=80,\n",
        "        batch_size=64,\n",
        "        callbacks=cb,\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    # Predict on test (log-space); invert transform\n",
        "    y_pred_log = model.predict(X_test_s).ravel()\n",
        "    y_pred = np.expm1(y_pred_log)\n",
        "    # clip negatives\n",
        "    y_pred = np.clip(y_pred, 0, None)\n",
        "\n",
        "    # Evaluate\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    nse_val = nse(y_test, y_pred)\n",
        "    print(f\"\\nTest RMSE: {rmse:.3f} m3/s\")\n",
        "    print(f\"Test NSE: {nse_val:.3f}\")\n",
        "\n",
        "    # Plot time series for first few basins in test set for visual check\n",
        "    # pick first 3 basins represented in test meta\n",
        "    sample_basins = meta_test['basin'].unique()[:3]\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    for i, basin_name in enumerate(sample_basins, 1):\n",
        "        mask_b = meta_test['basin'] == basin_name\n",
        "        dates_b = pd.to_datetime(meta_test.loc[mask_b, 'date'])\n",
        "        obs_b = y_test[mask_b]\n",
        "        pred_b = y_pred[mask_b]\n",
        "        plt.subplot(len(sample_basins), 1, i)\n",
        "        plt.plot(dates_b, obs_b, label='Observed', linewidth=1)\n",
        "        plt.plot(dates_b, pred_b, label='Predicted', linewidth=1)\n",
        "        plt.title(basin_name)\n",
        "        plt.ylabel(\"Streamflow (m3/s)\")\n",
        "        plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Scatter observed vs predicted\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.scatter(y_test, y_pred, alpha=0.4, s=10)\n",
        "    m = max(y_test.max(), y_pred.max())\n",
        "    plt.plot([0, m], [0, m], 'r--')\n",
        "    plt.xlabel(\"Observed (m3/s)\")\n",
        "    plt.ylabel(\"Predicted (m3/s)\")\n",
        "    plt.title(f\"Observed vs Predicted (RMSE={rmse:.2f}, NSE={nse_val:.2f})\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Export test predictions to Excel\n",
        "    out_df = meta_test.copy()\n",
        "    out_df['observed_streamflow_m3s'] = y_test\n",
        "    out_df['predicted_streamflow_m3s'] = y_pred\n",
        "    out_path = \"lstm_runoff_predictions.xlsx\"\n",
        "    out_df.to_excel(out_path, index=False)\n",
        "    print(f\"Exported test predictions to: {out_path}\")\n",
        "\n",
        "    # Save training history plot\n",
        "    plt.figure()\n",
        "    plt.plot(history.history['loss'], label='train_loss')\n",
        "    plt.plot(history.history['val_loss'], label='val_loss')\n",
        "    plt.yscale('log')\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss (MSE, log scale)\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Training history\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"training_history_runoff.png\", dpi=150)\n",
        "    print(\"Saved training history plot: training_history_runoff.png\")\n",
        "\n",
        "    print(\"Done.\")\n"
      ]
    }
  ]
}